{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Notebook\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The task is to produce a neural process which is tailored to solve a physical system.  In this case, the physical system to be solved is the heat diffusion across a two-dimensional grid.  There are three main changes I wish to make to the standard neural process.  These are listed below, along with a brief description of their physical motivation.\n",
    "\n",
    "#### 1. Convolutional Encoder and Decoder block \n",
    "Spatial equivariance is built into the system, since the heat diffusion function does not have a spatially dependent forcing term.  All terms are based on derivatives, which means the solution obeys spatial equivariance.  I hope to replicate this feature in the architecture, allowing for an easier learning process.\n",
    "#### 2. Learning using Privileged Information\n",
    "Learning using privileged information (LUPI) allows the model, while training, to have access to 'privileged information' (PI).  PI could be anything important the model should be aware of.  For example, if the total energy in the grid is conserved, imput this as PI.  When it comes to test time, the model does not have access to any PI.  The hope is that the model can infer what the PI should be (e.g. by figuring out what the total energy is and conserving it), making for a faster learning process.  There is a wide variety of PI to be used and experimented with.  A few more examples are: initial conditions, final conditions, decay constant, entropy measure.\n",
    "\n",
    "The way the PI is implemented is through an encoder which runs separately to the usual encoder.  The PI embedding is then aggregated with the embedding of the data using a residual neural network; we do not want the PI to dominate the learning, but merely to add a `first order correction' to the learning process.  The good thing about this structure is that the PI can be added to any encoder block (e.g. flat encoder or convolutional encoder)\n",
    "\n",
    "#### 3. Time-Order Respecting Aggregator\n",
    "In a neural process, the embeddings of the data at different times, $t_i$, are aggregated with a permutation invariant aggregator.  This is not usually useful for physical processes, as there tends to be a time-respecting process such as increase in entropy (in this case, diffusion of heat).  Therefore, it might be useful to reflect this in the aggregator.  The aggregator is such that there is no information leak from future to past - it imposes causality.\n",
    "\n",
    "The aggregator could also be designed to reflect temporal equivariance, for the same reasons as the spatial equivariance: the diffusion equation involves no terms which depend explicitly on time, but rather only the derivative with resepct to time.  If the model is temporally equivariant, it may perform much better on extrapolation tasks (as it is not completely `blind' when it heads out of the sample, having learnt temporal behaviour)\n",
    "\n",
    "One possible choice for this is to allow the model to `learn' these features by implementing a multi-head attention network.  However, with this option there is far less control over which physical concepts I am imposing.\n",
    "\n",
    "\n",
    "I hope these three changes will improve on the most basic vanilla neural process architecture to learn the heat diffusion behaviour over a two-dimensional grid, as they are all grounded in physical concepts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: dlopen(/usr/local/lib/python3.9/site-packages/torchvision/image.so, 0x0006): Symbol not found: (__ZN2at4_ops19empty_memory_format4callEN3c108ArrayRefIxEENS2_8optionalINS2_10ScalarTypeEEENS5_INS2_6LayoutEEENS5_INS2_6DeviceEEENS5_IbEENS5_INS2_12MemoryFormatEEE)\n",
      "  Referenced from: '/usr/local/lib/python3.9/site-packages/torchvision/image.so'\n",
      "  Expected in: '/usr/local/lib/python3.9/site-packages/torch/lib/libtorch_cpu.dylib'\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from scipy.integrate import odeint\n",
    "\n",
    "\n",
    "# grab the neural process functions from Emilien Dupont's library called neural-processes\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, \"./neural-processes\")\n",
    "\n",
    "# neural_process.py and training.py exist in neural-processes folder\n",
    "import neural_process\n",
    "from neural_process import NeuralProcessConv, NeuralProcess\n",
    "from training import NeuralProcessTrainer\n",
    "from utils import context_target_split\n",
    "from heat_diffusion_dataset import Initial_Conditions, Diffusion_Data, RestoredData\n",
    "from visualise import *\n",
    "\n",
    "# device is cuda something something ?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diffusion Data\n",
    "\n",
    "Heat Diffusion data was chosen as a suitable dataset to test my model.  The equation which the data follows is \n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{\\partial u(x, y, t)}{\\partial t} = D \\nabla^2 u(x, y, t)\n",
    "\\end{equation} \n",
    "\n",
    "The boundary conditions are chosen to be Neumann Boundary Conditions, specifying the normal gradient to be zero at the boundaries\n",
    "\n",
    "\\begin{equation}\n",
    "\\left. \\frac{\\partial u}{\\partial x} \\right|_{x = 0, L} = \\left. \\frac{\\partial u}{\\partial y}\\right|_{y=0, L} = 0\n",
    "\\end{equation}\n",
    "\n",
    "These boundary conditions ensure heat remains inside the grid and cannot escape (the flux through the boundary is zero).  There are no sources or sinks, so the total heat energy in the grid is conserved.\n",
    "\n",
    "The variation between datasets lies in the initial conditions.  There are three parameters for the initial conditions which are changed. \n",
    "1. Initial temperature \n",
    "2. Location of initial temperature spike\n",
    "3. Broadness of initial temperature spike \n",
    "\n",
    "The overall heat energy in the grid therefore can change from dataset to dataset, but remains constant within each one.  The diffusion coefficient is also the same for each dataset.  This could replicate, for example, heat diffusion in a fixed medium with varying initial conditions.\n",
    "\n",
    "Finite difference method (FDM) is used to solve equation 1.  The Laplacian is calculated using the five-point stencil finite difference method *Appendix.  This posed a difficulty when the initial conditions contained a discontinuous jump in temperature because Laplacian would become very large near the jump points.  To solve this issue, instead of implementing a different more advanced solver such as finite element methods (which may take a longer time to compute), a Gaussian filter was applied to smooth the initial conditions *Appendix.  The Gaussian filter was imported from `scipy.ndimage` module.\n",
    "\n",
    "FDM becomes unstable when $\\Delta t \\leq \\frac{\\Delta x^2}{4D}$ *appendix, reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimensions = {\n",
    "    't_dim' : 1,\n",
    "    'y_dim' : 2500,\n",
    "    'r_dim' : 128,\n",
    "    'h_dim' : 128,\n",
    "    'z_dim' : 128,\n",
    "    'max_iter_time' : 100,\n",
    "    'grid_size' : 50,\n",
    "    'num_samples' : 40,\n",
    "    'num_context' : 30,\n",
    "    'num_target' : 30,\n",
    "    'batch_size' : 2,\n",
    "    'num_channels' : 16,\n",
    "    'pi_dim' : 4\n",
    "}\n",
    "\n",
    "assert dimensions['grid_size']**2 == dimensions['y_dim']\n",
    "assert dimensions['num_context'] + dimensions['num_target'] <= dimensions['max_iter_time']\n",
    "\n",
    "# parameters\n",
    "grid_size = dimensions['grid_size']\n",
    "num_samples = dimensions['num_samples']\n",
    "square_range = (5, 15) # side length of initial hot square\n",
    "temp_range = (1.0, 2.0)\n",
    "diffusion_coef = 0.25 * dimensions['max_iter_time'] # upper limit for stable FDM solver\n",
    "\n",
    "assert diffusion_coef <= 0.25 * dimensions['max_iter_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "''' \n",
    "RUN TO RE-GENERATE DATA\n",
    "'''\n",
    "\n",
    "initial_conditions = Initial_Conditions(\n",
    "    max_iter_time=dimensions['max_iter_time'], grid_size=grid_size\n",
    ")\n",
    "\n",
    "meta_data = Diffusion_Data(\n",
    "    num_samples=num_samples,\n",
    "    max_iter_time=dimensions['max_iter_time'],\n",
    "    grid_size=grid_size,\n",
    "    initial_conditions=initial_conditions,\n",
    "    square_range=square_range,\n",
    "    temp_range=temp_range,\n",
    "    diffusion_coef=diffusion_coef,\n",
    "    sigma=3\n",
    ")\n",
    "\n",
    "time_array = meta_data.time_array\n",
    "meta_data.visualise_solution(show_until=1, i=0)\n",
    "\n",
    "# meta_data.save_tensors()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FLAT NEURAL PROCESS TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Avg_loss: 111389.21796875\n",
      "Epoch: 1, Avg_loss: 98588.783203125\n",
      "Epoch: 2, Avg_loss: 68297.510546875\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [4], line 16\u001b[0m\n\u001b[1;32m      5\u001b[0m np_trainer \u001b[38;5;241m=\u001b[39m NeuralProcessTrainer(\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      7\u001b[0m     neuralprocess,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m     is_lupi\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     13\u001b[0m )\n\u001b[1;32m     15\u001b[0m neuralprocess\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m \u001b[43mnp_trainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/part_III_project/./neural-processes/training.py:136\u001b[0m, in \u001b[0;36mNeuralProcessTrainer.train\u001b[0;34m(self, data_loader, epochs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     (\n\u001b[1;32m    120\u001b[0m         x_context,\n\u001b[1;32m    121\u001b[0m         y_context,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    125\u001b[0m         _,\n\u001b[1;32m    126\u001b[0m     ) \u001b[39m=\u001b[39m context_target_split(x, y, pi, num_context, num_extra_target)\n\u001b[1;32m    128\u001b[0m     p_y_pred, q_target, q_context \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mneural_process(\n\u001b[1;32m    129\u001b[0m         x_context,\n\u001b[1;32m    130\u001b[0m         y_context,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    134\u001b[0m         pi_target\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    135\u001b[0m     )\n\u001b[0;32m--> 136\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_loss(p_y_pred, y_target, q_target, q_context)\n\u001b[1;32m    137\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m    138\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/Documents/part_III_project/./neural-processes/training.py:177\u001b[0m, in \u001b[0;36mNeuralProcessTrainer._loss\u001b[0;34m(self, p_y_pred, y_target, q_target, q_context)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[39mComputes Neural Process loss.\u001b[39;00m\n\u001b[1;32m    155\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[39mprivileged information loss\u001b[39;00m\n\u001b[1;32m    174\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    175\u001b[0m \u001b[39m# Log likelihood has shape (batch_size, num_target, y_dim). Take mean\u001b[39;00m\n\u001b[1;32m    176\u001b[0m \u001b[39m# over batch and sum over number of targets and dimensions of y\u001b[39;00m\n\u001b[0;32m--> 177\u001b[0m log_likelihood \u001b[39m=\u001b[39m p_y_pred\u001b[39m.\u001b[39;49mlog_prob(y_target)\u001b[39m.\u001b[39mmean(dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\u001b[39m.\u001b[39msum()\n\u001b[1;32m    178\u001b[0m \u001b[39m# KL has shape (batch_size, r_dim). Take mean over batch and sum over\u001b[39;00m\n\u001b[1;32m    179\u001b[0m \u001b[39m# r_dim (since r_dim is dimension of normal distribution)\u001b[39;00m\n\u001b[1;32m    180\u001b[0m kl \u001b[39m=\u001b[39m kl_divergence(q_target, q_context)\u001b[39m.\u001b[39mmean(dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\u001b[39m.\u001b[39msum()\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/torch/distributions/normal.py:79\u001b[0m, in \u001b[0;36mNormal.log_prob\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlog_prob\u001b[39m(\u001b[39mself\u001b[39m, value):\n\u001b[1;32m     78\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_args:\n\u001b[0;32m---> 79\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_sample(value)\n\u001b[1;32m     80\u001b[0m     \u001b[39m# compute the variance\u001b[39;00m\n\u001b[1;32m     81\u001b[0m     var \u001b[39m=\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscale \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m \u001b[39m2\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/torch/distributions/distribution.py:292\u001b[0m, in \u001b[0;36mDistribution._validate_sample\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    290\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    291\u001b[0m \u001b[39massert\u001b[39;00m support \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 292\u001b[0m valid \u001b[39m=\u001b[39m support\u001b[39m.\u001b[39;49mcheck(value)\n\u001b[1;32m    293\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m valid\u001b[39m.\u001b[39mall():\n\u001b[1;32m    294\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    295\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mExpected value argument \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    296\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(value)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m of shape \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtuple\u001b[39m(value\u001b[39m.\u001b[39mshape)\u001b[39m}\u001b[39;00m\u001b[39m) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    299\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbut found invalid values:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mvalue\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    300\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/torch/distributions/constraints.py:308\u001b[0m, in \u001b[0;36m_Real.check\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcheck\u001b[39m(\u001b[39mself\u001b[39m, value):\n\u001b[0;32m--> 308\u001b[0m     \u001b[39mreturn\u001b[39;00m value \u001b[39m==\u001b[39;49m value\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "neuralprocess = NeuralProcess(dimensions)\n",
    "\n",
    "data_loader = DataLoader(meta_data, batch_size=dimensions['batch_size'], shuffle=True)\n",
    "optimizer = torch.optim.Adam(neuralprocess.parameters(), lr=3e-4)\n",
    "np_trainer = NeuralProcessTrainer(\n",
    "    \"cuda\",\n",
    "    neuralprocess,\n",
    "    optimizer,\n",
    "    num_context_range=(dimensions['num_context'], dimensions['num_context']),\n",
    "    num_extra_target_range=(dimensions['num_target'], dimensions['num_target']),\n",
    "    print_freq=200,\n",
    "    is_lupi=False\n",
    ")\n",
    "\n",
    "neuralprocess.training = True\n",
    "np_trainer.train(data_loader, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CONVOLUTIONAL NEURAL PROCESS TRAINING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameters\n",
    "- h_dim\n",
    "- r_dim\n",
    "- z_dim\n",
    "- batch_size\n",
    "- num_context\n",
    "- num_target\n",
    "- lr\n",
    "\n",
    "#### Hidden Hyperparameters\n",
    "- Number of linear layers after convolution in Net\n",
    "- Number of linear layers in TransposeConvNet\n",
    "- Number of channels in Net and TransposeConvNet\n",
    "- Number of layers in Net and TransposeConvNet\n",
    "- Kernels, Dilations, Paddings\n",
    "\n",
    "#### Current Convolution Summary \n",
    "\n",
    "Net: 2 layers with 32 'hidden' channels, followed by 3 Linear layers with h_dim hidden.\n",
    "\n",
    "TNet: 1 Linear layer, followed by 2 transpose convolutional layers with 32 'hidden' channels.\n",
    "\n",
    "\n",
    "#### Purpose of the Convolution\n",
    "- Create spatially equivariant features in the grids\n",
    "- Encourage principles of locality when learning\n",
    "- Temporal equivariance in solution (periodicity encouraged?) - this is not happening currently as the temporal aspect only enters after the convolution\n",
    "\n",
    "TODO: before moving on \n",
    "- Debug the conv neural process (write some tests?)\n",
    "- Implement tests on standard NP \n",
    "- Compare performance  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Avg_loss: 288995.9171875\n",
      "Epoch: 1, Avg_loss: 147710.168359375\n",
      "Epoch: 2, Avg_loss: 125935.92109375\n",
      "Epoch: 3, Avg_loss: 114559.442578125\n",
      "Epoch: 4, Avg_loss: 107704.373046875\n",
      "Epoch: 5, Avg_loss: 103107.4390625\n",
      "Epoch: 6, Avg_loss: 99955.5234375\n",
      "Epoch: 7, Avg_loss: 97363.63203125\n",
      "Epoch: 8, Avg_loss: 95000.76796875\n",
      "iteration 200, loss 98526.211\n",
      "Epoch: 9, Avg_loss: 91849.090625\n",
      "Epoch: 10, Avg_loss: 89235.419921875\n",
      "Epoch: 11, Avg_loss: 87722.030859375\n",
      "Epoch: 12, Avg_loss: 85916.435546875\n",
      "Epoch: 13, Avg_loss: 83997.862109375\n",
      "Epoch: 14, Avg_loss: 82251.7640625\n",
      "Epoch: 15, Avg_loss: 81641.319140625\n",
      "Epoch: 16, Avg_loss: 79553.387109375\n",
      "Epoch: 17, Avg_loss: 77704.1724609375\n",
      "Epoch: 18, Avg_loss: 76206.75390625\n",
      "iteration 400, loss 82851.445\n",
      "Epoch: 19, Avg_loss: 74425.861328125\n",
      "Epoch: 20, Avg_loss: 71660.9306640625\n",
      "Epoch: 21, Avg_loss: 69009.2572265625\n",
      "Epoch: 22, Avg_loss: 64302.78359375\n",
      "Epoch: 23, Avg_loss: 59710.8216796875\n",
      "Epoch: 24, Avg_loss: 56320.0447265625\n",
      "Epoch: 25, Avg_loss: 52865.9951171875\n",
      "Epoch: 26, Avg_loss: 50411.141015625\n",
      "Epoch: 27, Avg_loss: 47730.8158203125\n",
      "Epoch: 28, Avg_loss: 45637.590234375\n",
      "iteration 600, loss 47190.836\n",
      "Epoch: 29, Avg_loss: 43453.8302734375\n",
      "Epoch: 30, Avg_loss: 40836.6443359375\n",
      "Epoch: 31, Avg_loss: 39250.87412109375\n",
      "Epoch: 32, Avg_loss: 37274.55078125\n",
      "Epoch: 33, Avg_loss: 35783.8130859375\n",
      "Epoch: 34, Avg_loss: 34117.9671875\n",
      "Epoch: 35, Avg_loss: 32399.57998046875\n",
      "Epoch: 36, Avg_loss: 30697.001171875\n",
      "Epoch: 37, Avg_loss: 29179.22373046875\n",
      "Epoch: 38, Avg_loss: 26760.94931640625\n",
      "iteration 800, loss 29397.271\n",
      "Epoch: 39, Avg_loss: 25068.6552734375\n",
      "Epoch: 40, Avg_loss: 23490.62021484375\n",
      "Epoch: 41, Avg_loss: 21440.517626953126\n",
      "Epoch: 42, Avg_loss: 19190.584375\n",
      "Epoch: 43, Avg_loss: 18016.958154296874\n",
      "Epoch: 44, Avg_loss: 16274.6666015625\n",
      "Epoch: 45, Avg_loss: 13503.869775390625\n",
      "Epoch: 46, Avg_loss: 12658.81611328125\n",
      "Epoch: 47, Avg_loss: 10413.876350402832\n",
      "Epoch: 48, Avg_loss: 7950.735544908047\n",
      "iteration 1000, loss 3953.128\n",
      "Epoch: 49, Avg_loss: 6754.01782836914\n",
      "Epoch: 50, Avg_loss: 5286.308056640625\n",
      "Epoch: 51, Avg_loss: 2661.740653991699\n",
      "Epoch: 52, Avg_loss: 562.9486358642578\n",
      "Epoch: 53, Avg_loss: -1150.6070163726806\n",
      "Epoch: 54, Avg_loss: -3491.589168548584\n",
      "Epoch: 55, Avg_loss: -6490.066397094726\n",
      "Epoch: 56, Avg_loss: -8630.937602233887\n",
      "Epoch: 57, Avg_loss: -9865.003833007813\n",
      "Epoch: 58, Avg_loss: -11722.13151550293\n",
      "iteration 1200, loss -20112.949\n",
      "Epoch: 59, Avg_loss: -13667.069445800782\n",
      "Epoch: 60, Avg_loss: -15401.776623535156\n",
      "Epoch: 61, Avg_loss: -17908.52814941406\n",
      "Epoch: 62, Avg_loss: -21790.136865234374\n",
      "Epoch: 63, Avg_loss: -22121.484130859375\n",
      "Epoch: 64, Avg_loss: -24462.426171875\n",
      "Epoch: 65, Avg_loss: -27141.86494140625\n",
      "Epoch: 66, Avg_loss: -28902.98232421875\n",
      "Epoch: 67, Avg_loss: -31143.725\n",
      "Epoch: 68, Avg_loss: -34814.70927734375\n",
      "iteration 1400, loss -40487.539\n",
      "Epoch: 69, Avg_loss: -36467.576171875\n",
      "Epoch: 70, Avg_loss: -38047.7205078125\n",
      "Epoch: 71, Avg_loss: -40129.9626953125\n",
      "Epoch: 72, Avg_loss: -43607.5353515625\n",
      "Epoch: 73, Avg_loss: -44234.67265625\n",
      "Epoch: 74, Avg_loss: -47645.18046875\n",
      "Epoch: 75, Avg_loss: -48703.311328125\n",
      "Epoch: 76, Avg_loss: -51101.9662109375\n",
      "Epoch: 77, Avg_loss: -52488.2451171875\n",
      "Epoch: 78, Avg_loss: -57738.4607421875\n",
      "iteration 1600, loss -62452.789\n",
      "Epoch: 79, Avg_loss: -59018.59453125\n",
      "Epoch: 80, Avg_loss: -64182.735546875\n",
      "Epoch: 81, Avg_loss: -64531.58984375\n",
      "Epoch: 82, Avg_loss: -67309.0421875\n",
      "Epoch: 83, Avg_loss: -70767.705078125\n",
      "Epoch: 84, Avg_loss: -72792.7576171875\n",
      "Epoch: 85, Avg_loss: -76429.214453125\n",
      "Epoch: 86, Avg_loss: -75094.294921875\n",
      "Epoch: 87, Avg_loss: -74661.0140625\n",
      "Epoch: 88, Avg_loss: -76535.28359375\n",
      "iteration 1800, loss -89307.219\n",
      "Epoch: 89, Avg_loss: -79328.436328125\n",
      "Epoch: 90, Avg_loss: -81265.9703125\n",
      "Epoch: 91, Avg_loss: -88414.7703125\n",
      "Epoch: 92, Avg_loss: -92298.751953125\n",
      "Epoch: 93, Avg_loss: -95252.79453125\n",
      "Epoch: 94, Avg_loss: -94927.0451171875\n",
      "Epoch: 95, Avg_loss: -99177.73203125\n",
      "Epoch: 96, Avg_loss: -101462.213671875\n",
      "Epoch: 97, Avg_loss: -104559.9484375\n",
      "Epoch: 98, Avg_loss: -108058.41953125\n",
      "iteration 2000, loss -103235.852\n",
      "Epoch: 99, Avg_loss: -109459.02265625\n",
      "Epoch: 100, Avg_loss: -112992.848828125\n",
      "Epoch: 101, Avg_loss: -112894.7189453125\n",
      "Epoch: 102, Avg_loss: -115693.4046875\n",
      "Epoch: 103, Avg_loss: -116685.444921875\n",
      "Epoch: 104, Avg_loss: -120808.483984375\n",
      "Epoch: 105, Avg_loss: -123990.042578125\n",
      "Epoch: 106, Avg_loss: -123590.5091796875\n",
      "Epoch: 107, Avg_loss: -119281.74921875\n",
      "Epoch: 108, Avg_loss: -121119.6541015625\n",
      "iteration 2200, loss -116803.672\n",
      "Epoch: 109, Avg_loss: -117513.865234375\n",
      "Epoch: 110, Avg_loss: -124696.945703125\n",
      "Epoch: 111, Avg_loss: -133739.6109375\n",
      "Epoch: 112, Avg_loss: -138319.8453125\n",
      "Epoch: 113, Avg_loss: -138980.023828125\n",
      "Epoch: 114, Avg_loss: -141448.1078125\n",
      "Epoch: 115, Avg_loss: -145227.244921875\n",
      "Epoch: 116, Avg_loss: -142675.416796875\n",
      "Epoch: 117, Avg_loss: -149138.04296875\n",
      "Epoch: 118, Avg_loss: -152146.7796875\n",
      "iteration 2400, loss -141238.203\n",
      "Epoch: 119, Avg_loss: -152550.267578125\n",
      "Epoch: 120, Avg_loss: -161487.66484375\n",
      "Epoch: 121, Avg_loss: -159307.7359375\n",
      "Epoch: 122, Avg_loss: -165304.98984375\n",
      "Epoch: 123, Avg_loss: -165965.28828125\n",
      "Epoch: 124, Avg_loss: -169824.7453125\n",
      "Epoch: 125, Avg_loss: -167149.26533203124\n",
      "Epoch: 126, Avg_loss: -169693.35234375\n",
      "Epoch: 127, Avg_loss: -164434.10947265624\n",
      "Epoch: 128, Avg_loss: -177326.08203125\n",
      "iteration 2600, loss -192474.047\n",
      "Epoch: 129, Avg_loss: -182418.8171875\n",
      "Epoch: 130, Avg_loss: -181309.108984375\n",
      "Epoch: 131, Avg_loss: -183613.4265625\n",
      "Epoch: 132, Avg_loss: -188061.49921875\n",
      "Epoch: 133, Avg_loss: -190856.3609375\n",
      "Epoch: 134, Avg_loss: -196445.16875\n",
      "Epoch: 135, Avg_loss: -191083.07109375\n",
      "Epoch: 136, Avg_loss: -198073.05234375\n",
      "Epoch: 137, Avg_loss: -189785.67265625\n",
      "Epoch: 138, Avg_loss: -187531.60361328124\n",
      "iteration 2800, loss -71786.016\n",
      "Epoch: 139, Avg_loss: -201872.47890625\n",
      "Epoch: 140, Avg_loss: -206896.3375\n",
      "Epoch: 141, Avg_loss: -209017.15859375\n",
      "Epoch: 142, Avg_loss: -208486.9140625\n",
      "Epoch: 143, Avg_loss: -190389.02890625\n",
      "Epoch: 144, Avg_loss: -179005.3505859375\n",
      "Epoch: 145, Avg_loss: -187037.23671875\n",
      "Epoch: 146, Avg_loss: -190185.1439453125\n",
      "Epoch: 147, Avg_loss: -203209.828125\n",
      "Epoch: 148, Avg_loss: -209041.5984375\n",
      "iteration 3000, loss -221900.391\n",
      "Epoch: 149, Avg_loss: -187657.590625\n",
      "Epoch: 150, Avg_loss: -177686.39453125\n",
      "Epoch: 151, Avg_loss: -111380.14228515625\n",
      "Epoch: 152, Avg_loss: -96835.828125\n",
      "Epoch: 153, Avg_loss: -39254.21826171875\n",
      "Epoch: 154, Avg_loss: -166543.06796875\n",
      "Epoch: 155, Avg_loss: -197127.9140625\n",
      "Epoch: 156, Avg_loss: -199884.885546875\n",
      "Epoch: 157, Avg_loss: -201475.7140625\n",
      "Epoch: 158, Avg_loss: -205414.00390625\n",
      "iteration 3200, loss -174421.781\n",
      "Epoch: 159, Avg_loss: -211354.36796875\n",
      "Epoch: 160, Avg_loss: -210124.45859375\n",
      "Epoch: 161, Avg_loss: -218140.29921875\n",
      "Epoch: 162, Avg_loss: -203322.04921875\n",
      "Epoch: 163, Avg_loss: -215959.1703125\n",
      "Epoch: 164, Avg_loss: -218104.339453125\n",
      "Epoch: 165, Avg_loss: -220922.41796875\n",
      "Epoch: 166, Avg_loss: -216029.1671875\n",
      "Epoch: 167, Avg_loss: -203011.6984375\n",
      "Epoch: 168, Avg_loss: -208688.5439453125\n",
      "iteration 3400, loss -239291.812\n",
      "Epoch: 169, Avg_loss: -230276.6890625\n",
      "Epoch: 170, Avg_loss: -225247.411328125\n",
      "Epoch: 171, Avg_loss: -233938.03828125\n",
      "Epoch: 172, Avg_loss: -216284.7119140625\n",
      "Epoch: 173, Avg_loss: -234463.859375\n",
      "Epoch: 174, Avg_loss: -221538.537890625\n",
      "Epoch: 175, Avg_loss: -212404.10078125\n",
      "Epoch: 176, Avg_loss: -228087.918359375\n",
      "Epoch: 177, Avg_loss: -233213.0859375\n",
      "Epoch: 178, Avg_loss: -240203.58984375\n",
      "iteration 3600, loss -244241.188\n",
      "Epoch: 179, Avg_loss: -243251.01875\n",
      "Epoch: 180, Avg_loss: -233654.696484375\n",
      "Epoch: 181, Avg_loss: -236967.659375\n",
      "Epoch: 182, Avg_loss: -227786.34375\n",
      "Epoch: 183, Avg_loss: -243613.44375\n",
      "Epoch: 184, Avg_loss: -245952.284375\n",
      "Epoch: 185, Avg_loss: -250452.65390625\n",
      "Epoch: 186, Avg_loss: -233072.076171875\n",
      "Epoch: 187, Avg_loss: -236259.31484375\n",
      "Epoch: 188, Avg_loss: -237523.511328125\n",
      "iteration 3800, loss -262756.062\n",
      "Epoch: 189, Avg_loss: -257113.31328125\n",
      "Epoch: 190, Avg_loss: -239669.351171875\n",
      "Epoch: 191, Avg_loss: -236441.558984375\n",
      "Epoch: 192, Avg_loss: -248133.1828125\n",
      "Epoch: 193, Avg_loss: -253554.02734375\n",
      "Epoch: 194, Avg_loss: -261156.9296875\n",
      "Epoch: 195, Avg_loss: -264618.534375\n",
      "Epoch: 196, Avg_loss: -248363.2765625\n",
      "Epoch: 197, Avg_loss: -263925.6984375\n",
      "Epoch: 198, Avg_loss: -248697.8109375\n",
      "iteration 4000, loss -272706.906\n",
      "Epoch: 199, Avg_loss: -223379.9375\n",
      "Epoch: 200, Avg_loss: -238872.9462890625\n",
      "Epoch: 201, Avg_loss: -195846.7\n",
      "Epoch: 202, Avg_loss: -235273.6275390625\n",
      "Epoch: 203, Avg_loss: -249569.2765625\n",
      "Epoch: 204, Avg_loss: -253698.340625\n",
      "Epoch: 205, Avg_loss: -183480.0892578125\n",
      "Epoch: 206, Avg_loss: -238089.3953125\n",
      "Epoch: 207, Avg_loss: -251405.71953125\n",
      "Epoch: 208, Avg_loss: -255003.8244140625\n",
      "iteration 4200, loss -251827.078\n",
      "Epoch: 209, Avg_loss: -241049.0763671875\n",
      "Epoch: 210, Avg_loss: -240373.21484375\n",
      "Epoch: 211, Avg_loss: -256242.0046875\n",
      "Epoch: 212, Avg_loss: -249106.1951171875\n",
      "Epoch: 213, Avg_loss: -262947.115234375\n",
      "Epoch: 214, Avg_loss: -253781.5107421875\n",
      "Epoch: 215, Avg_loss: -253478.778125\n",
      "Epoch: 216, Avg_loss: -262836.33046875\n",
      "Epoch: 217, Avg_loss: -270687.2359375\n",
      "Epoch: 218, Avg_loss: -270588.6375\n",
      "iteration 4400, loss -265313.406\n",
      "Epoch: 219, Avg_loss: -275402.00078125\n",
      "Epoch: 220, Avg_loss: -276112.984375\n",
      "Epoch: 221, Avg_loss: -269173.6892578125\n",
      "Epoch: 222, Avg_loss: -279948.02578125\n",
      "Epoch: 223, Avg_loss: -263171.58203125\n",
      "Epoch: 224, Avg_loss: -280456.8453125\n",
      "Epoch: 225, Avg_loss: -248550.274609375\n",
      "Epoch: 226, Avg_loss: -264691.38046875\n",
      "Epoch: 227, Avg_loss: -280258.6125\n",
      "Epoch: 228, Avg_loss: -268583.13359375\n",
      "iteration 4600, loss -300549.281\n",
      "Epoch: 229, Avg_loss: -221333.121875\n",
      "Epoch: 230, Avg_loss: -242374.1255859375\n",
      "Epoch: 231, Avg_loss: -251084.2734375\n",
      "Epoch: 232, Avg_loss: -271770.4140625\n",
      "Epoch: 233, Avg_loss: -271313.675390625\n",
      "Epoch: 234, Avg_loss: -261998.759375\n",
      "Epoch: 235, Avg_loss: -242375.52265625\n",
      "Epoch: 236, Avg_loss: -267566.3265625\n",
      "Epoch: 237, Avg_loss: -270156.9515625\n",
      "Epoch: 238, Avg_loss: -271532.53173828125\n",
      "iteration 4800, loss -179414.594\n",
      "Epoch: 239, Avg_loss: -267412.819921875\n",
      "Epoch: 240, Avg_loss: -262381.5953460693\n",
      "Epoch: 241, Avg_loss: -280948.46640625\n",
      "Epoch: 242, Avg_loss: -271875.5492263794\n",
      "Epoch: 243, Avg_loss: -279892.41484375\n",
      "Epoch: 244, Avg_loss: -271989.52734375\n",
      "Epoch: 245, Avg_loss: -270250.689453125\n",
      "Epoch: 246, Avg_loss: -278096.2150634766\n",
      "Epoch: 247, Avg_loss: -257480.76137695313\n",
      "Epoch: 248, Avg_loss: -281521.421875\n",
      "iteration 5000, loss -128559.148\n",
      "Epoch: 249, Avg_loss: -273435.828515625\n",
      "Epoch: 250, Avg_loss: -278254.322265625\n",
      "Epoch: 251, Avg_loss: -269311.3404296875\n",
      "Epoch: 252, Avg_loss: -289627.35703125\n",
      "Epoch: 253, Avg_loss: -291705.61796875\n",
      "Epoch: 254, Avg_loss: -287891.50703125\n",
      "Epoch: 255, Avg_loss: -274802.6179443359\n",
      "Epoch: 256, Avg_loss: -202905.3203125\n",
      "Epoch: 257, Avg_loss: -127757.84921875\n",
      "Epoch: 258, Avg_loss: -214978.78715820314\n",
      "iteration 5200, loss 369004.469\n",
      "Epoch: 259, Avg_loss: -46220.2798828125\n",
      "Epoch: 260, Avg_loss: -173537.272265625\n",
      "Epoch: 261, Avg_loss: -215545.55991210937\n",
      "Epoch: 262, Avg_loss: -214322.0486328125\n",
      "Epoch: 263, Avg_loss: -264507.965234375\n",
      "Epoch: 264, Avg_loss: -272954.017578125\n",
      "Epoch: 265, Avg_loss: -271391.05078125\n",
      "Epoch: 266, Avg_loss: -263192.56494140625\n",
      "Epoch: 267, Avg_loss: -273266.9921875\n",
      "Epoch: 268, Avg_loss: -247111.52197265625\n",
      "iteration 5400, loss -278761.531\n",
      "Epoch: 269, Avg_loss: -283476.9421875\n",
      "Epoch: 270, Avg_loss: -265860.042578125\n",
      "Epoch: 271, Avg_loss: -280079.78203125\n",
      "Epoch: 272, Avg_loss: -222801.28203125\n",
      "Epoch: 273, Avg_loss: -269052.269921875\n",
      "Epoch: 274, Avg_loss: -272774.611328125\n",
      "Epoch: 275, Avg_loss: -272023.566796875\n",
      "Epoch: 276, Avg_loss: -287559.9421875\n",
      "Epoch: 277, Avg_loss: -252317.11875\n",
      "Epoch: 278, Avg_loss: -278162.5765625\n",
      "iteration 5600, loss -283667.688\n",
      "Epoch: 279, Avg_loss: -268513.6649414062\n",
      "Epoch: 280, Avg_loss: -285313.0421875\n",
      "Epoch: 281, Avg_loss: -265626.6419921875\n",
      "Epoch: 282, Avg_loss: -280028.956640625\n",
      "Epoch: 283, Avg_loss: -281233.48125\n",
      "Epoch: 284, Avg_loss: -296856.48203125\n",
      "Epoch: 285, Avg_loss: -287345.575390625\n",
      "Epoch: 286, Avg_loss: -285946.7853515625\n",
      "Epoch: 287, Avg_loss: -294600.09140625\n",
      "Epoch: 288, Avg_loss: -288319.57265625\n",
      "iteration 5800, loss -317429.406\n",
      "Epoch: 289, Avg_loss: -287738.306640625\n",
      "Epoch: 290, Avg_loss: -276016.574609375\n",
      "Epoch: 291, Avg_loss: -272973.19375\n",
      "Epoch: 292, Avg_loss: -276775.11875\n",
      "Epoch: 293, Avg_loss: -288693.05546875\n",
      "Epoch: 294, Avg_loss: -270152.568359375\n",
      "Epoch: 295, Avg_loss: -295950.26328125\n",
      "Epoch: 296, Avg_loss: -295445.83046875\n",
      "Epoch: 297, Avg_loss: -300448.57421875\n",
      "Epoch: 298, Avg_loss: -282143.334375\n",
      "iteration 6000, loss -277875.812\n",
      "Epoch: 299, Avg_loss: -293903.775\n",
      "Epoch: 300, Avg_loss: -279858.93125\n",
      "Epoch: 301, Avg_loss: -274914.629296875\n",
      "Epoch: 302, Avg_loss: -304611.11796875\n",
      "Epoch: 303, Avg_loss: -302479.83359375\n",
      "Epoch: 304, Avg_loss: -249884.303515625\n",
      "Epoch: 305, Avg_loss: -249180.66630859376\n",
      "Epoch: 306, Avg_loss: -281804.600390625\n",
      "Epoch: 307, Avg_loss: -295716.56484375\n",
      "Epoch: 308, Avg_loss: -233629.15546875\n",
      "iteration 6200, loss -277655.500\n",
      "Epoch: 309, Avg_loss: -260313.540234375\n",
      "Epoch: 310, Avg_loss: -270870.8462890625\n",
      "Epoch: 311, Avg_loss: -295414.39921875\n",
      "Epoch: 312, Avg_loss: -286987.24765625\n",
      "Epoch: 313, Avg_loss: -278596.8955078125\n",
      "Epoch: 314, Avg_loss: -295727.6375\n",
      "Epoch: 315, Avg_loss: -304223.48046875\n",
      "Epoch: 316, Avg_loss: -299566.13828125\n",
      "Epoch: 317, Avg_loss: -308749.40859375\n",
      "Epoch: 318, Avg_loss: -295479.61875\n",
      "iteration 6400, loss -280511.031\n",
      "Epoch: 319, Avg_loss: -307052.21875\n",
      "Epoch: 320, Avg_loss: -307754.51328125\n",
      "Epoch: 321, Avg_loss: -275089.775\n",
      "Epoch: 322, Avg_loss: -304934.51953125\n",
      "Epoch: 323, Avg_loss: -301371.857421875\n",
      "Epoch: 324, Avg_loss: -304605.63671875\n",
      "Epoch: 325, Avg_loss: -297173.265625\n",
      "Epoch: 326, Avg_loss: -312797.95546875\n",
      "Epoch: 327, Avg_loss: -300362.13671875\n",
      "Epoch: 328, Avg_loss: -300913.372265625\n",
      "iteration 6600, loss -314616.000\n",
      "Epoch: 329, Avg_loss: -313121.84453125\n",
      "Epoch: 330, Avg_loss: -283208.937890625\n",
      "Epoch: 331, Avg_loss: -309118.48125\n",
      "Epoch: 332, Avg_loss: -303012.44296875\n",
      "Epoch: 333, Avg_loss: -310030.59375\n",
      "Epoch: 334, Avg_loss: -297198.73046875\n",
      "Epoch: 335, Avg_loss: -286089.178125\n",
      "Epoch: 336, Avg_loss: -289377.999609375\n",
      "Epoch: 337, Avg_loss: -276323.6783203125\n",
      "Epoch: 338, Avg_loss: -203716.7421875\n",
      "iteration 6800, loss -199333.281\n",
      "Epoch: 339, Avg_loss: -266066.50703125\n",
      "Epoch: 340, Avg_loss: -181836.42109375\n",
      "Epoch: 341, Avg_loss: -130682.98046875\n",
      "Epoch: 342, Avg_loss: -244392.0474609375\n",
      "Epoch: 343, Avg_loss: -254168.67744140624\n",
      "Epoch: 344, Avg_loss: -268841.859765625\n",
      "Epoch: 345, Avg_loss: -241922.4203125\n",
      "Epoch: 346, Avg_loss: -275786.26875\n",
      "Epoch: 347, Avg_loss: -295641.375\n",
      "Epoch: 348, Avg_loss: -282290.25703125\n",
      "iteration 7000, loss -299986.969\n",
      "Epoch: 349, Avg_loss: -300076.8546875\n",
      "Epoch: 350, Avg_loss: -301012.67109375\n",
      "Epoch: 351, Avg_loss: -308135.21171875\n",
      "Epoch: 352, Avg_loss: -282110.6016601563\n",
      "Epoch: 353, Avg_loss: -261305.859765625\n",
      "Epoch: 354, Avg_loss: -293677.9935546875\n",
      "Epoch: 355, Avg_loss: -309934.22578125\n",
      "Epoch: 356, Avg_loss: -308852.51640625\n",
      "Epoch: 357, Avg_loss: -240501.28828125\n",
      "Epoch: 358, Avg_loss: -295638.35546875\n",
      "iteration 7200, loss -304911.844\n",
      "Epoch: 359, Avg_loss: -219849.34609375\n",
      "Epoch: 360, Avg_loss: -244493.85078125\n",
      "Epoch: 361, Avg_loss: -292278.934375\n",
      "Epoch: 362, Avg_loss: -293061.98876953125\n",
      "Epoch: 363, Avg_loss: -281423.6509277344\n",
      "Epoch: 364, Avg_loss: -281075.24609375\n",
      "Epoch: 365, Avg_loss: -276219.3212890625\n",
      "Epoch: 366, Avg_loss: -283471.94427490234\n",
      "Epoch: 367, Avg_loss: -301917.66015625\n",
      "Epoch: 368, Avg_loss: -313755.1671875\n",
      "iteration 7400, loss -320084.062\n",
      "Epoch: 369, Avg_loss: -303822.75810546876\n",
      "Epoch: 370, Avg_loss: -294591.95859375\n",
      "Epoch: 371, Avg_loss: -300873.2001953125\n",
      "Epoch: 372, Avg_loss: -310235.56484375\n",
      "Epoch: 373, Avg_loss: -289739.7818359375\n",
      "Epoch: 374, Avg_loss: -304839.3251953125\n",
      "Epoch: 375, Avg_loss: -309740.5890625\n",
      "Epoch: 376, Avg_loss: -319715.4546875\n",
      "Epoch: 377, Avg_loss: -316761.1828125\n",
      "Epoch: 378, Avg_loss: -294026.378125\n",
      "iteration 7600, loss -249497.234\n",
      "Epoch: 379, Avg_loss: -253814.19765625\n",
      "Epoch: 380, Avg_loss: -306155.7890625\n",
      "Epoch: 381, Avg_loss: -314182.1515625\n",
      "Epoch: 382, Avg_loss: -308639.5859375\n",
      "Epoch: 383, Avg_loss: -302220.851953125\n",
      "Epoch: 384, Avg_loss: -313623.80234375\n",
      "Epoch: 385, Avg_loss: -308553.59453125\n",
      "Epoch: 386, Avg_loss: -259291.35703125\n",
      "Epoch: 387, Avg_loss: -314145.3734375\n",
      "Epoch: 388, Avg_loss: -310443.85234375\n",
      "iteration 7800, loss -342633.625\n",
      "Epoch: 389, Avg_loss: -295477.6068359375\n",
      "Epoch: 390, Avg_loss: -288956.26015625\n",
      "Epoch: 391, Avg_loss: -302124.27265625\n",
      "Epoch: 392, Avg_loss: -322675.9890625\n",
      "Epoch: 393, Avg_loss: -316475.008984375\n",
      "Epoch: 394, Avg_loss: -297337.1993164063\n",
      "Epoch: 395, Avg_loss: -321110.6046875\n",
      "Epoch: 396, Avg_loss: -312989.65625\n",
      "Epoch: 397, Avg_loss: -277664.98779296875\n",
      "Epoch: 398, Avg_loss: -311373.98203125\n",
      "iteration 8000, loss -298284.625\n",
      "Epoch: 399, Avg_loss: -230532.784375\n",
      "Epoch: 400, Avg_loss: -243099.040625\n",
      "Epoch: 401, Avg_loss: -238585.92958984376\n",
      "Epoch: 402, Avg_loss: -251074.15302734374\n",
      "Epoch: 403, Avg_loss: -279789.0625\n",
      "Epoch: 404, Avg_loss: -289907.05302734376\n",
      "Epoch: 405, Avg_loss: -305389.646484375\n",
      "Epoch: 406, Avg_loss: -222051.76640625\n",
      "Epoch: 407, Avg_loss: -292371.8858398438\n",
      "Epoch: 408, Avg_loss: -279354.2921875\n",
      "iteration 8200, loss -308591.000\n",
      "Epoch: 409, Avg_loss: -300876.18515625\n",
      "Epoch: 410, Avg_loss: -305674.0125\n",
      "Epoch: 411, Avg_loss: -301760.93359375\n",
      "Epoch: 412, Avg_loss: -311350.0693359375\n",
      "Epoch: 413, Avg_loss: -298110.3748046875\n",
      "Epoch: 414, Avg_loss: -302980.9765625\n",
      "Epoch: 415, Avg_loss: -289267.5703125\n",
      "Epoch: 416, Avg_loss: -309509.18876953126\n",
      "Epoch: 417, Avg_loss: -322136.634375\n",
      "Epoch: 418, Avg_loss: -274249.697265625\n",
      "iteration 8400, loss -338353.688\n",
      "Epoch: 419, Avg_loss: -303875.841015625\n",
      "Epoch: 420, Avg_loss: -301634.34921875\n",
      "Epoch: 421, Avg_loss: -300045.3414550781\n",
      "Epoch: 422, Avg_loss: -310007.45078125\n",
      "Epoch: 423, Avg_loss: -319197.42578125\n",
      "Epoch: 424, Avg_loss: -323704.7640625\n",
      "Epoch: 425, Avg_loss: -323162.25625\n",
      "Epoch: 426, Avg_loss: -297243.0109375\n",
      "Epoch: 427, Avg_loss: -284153.075\n",
      "Epoch: 428, Avg_loss: -263336.76171875\n",
      "iteration 8600, loss -297307.438\n",
      "Epoch: 429, Avg_loss: -297012.6065429688\n",
      "Epoch: 430, Avg_loss: -311016.4609375\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "TODO \n",
    "- put time into channels not flat layer DONE - also kept in flat layer\n",
    "- play with hyperparams until good outcome \n",
    "\"\"\"\n",
    "\n",
    "conv_neuralprocess = NeuralProcessConv(dimensions)\n",
    "\n",
    "data_loader = DataLoader(meta_data, batch_size=dimensions['batch_size'], shuffle=True)\n",
    "optimizer = torch.optim.Adam(conv_neuralprocess.parameters(), lr=1e-3)\n",
    "conv_np_trainer = NeuralProcessTrainer(\n",
    "    \"cuda\",\n",
    "    conv_neuralprocess,\n",
    "    optimizer,\n",
    "    num_context_range=(dimensions['num_context'], dimensions['num_context']),\n",
    "    num_extra_target_range=(dimensions['num_target'], dimensions['num_target']),\n",
    "    print_freq=200,\n",
    "    grid_size=dimensions['grid_size'],\n",
    ")\n",
    "\n",
    "conv_neuralprocess.training = True\n",
    "conv_np_trainer.train(data_loader, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L.U.P.I. FOR FLAT NP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Avg_loss: 111840.2515625\n",
      "Epoch: 1, Avg_loss: 95473.56796875\n",
      "Epoch: 2, Avg_loss: 69834.0685546875\n",
      "Epoch: 3, Avg_loss: 54715.08984375\n",
      "Epoch: 4, Avg_loss: 47185.208795166014\n",
      "Epoch: 5, Avg_loss: 46728.10993652344\n",
      "Epoch: 6, Avg_loss: 45734.45844726563\n",
      "Epoch: 7, Avg_loss: 45009.45872192383\n",
      "Epoch: 8, Avg_loss: 41163.71750183105\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [6], line 15\u001b[0m\n\u001b[1;32m      5\u001b[0m np_trainer_pi \u001b[38;5;241m=\u001b[39m NeuralProcessTrainer(\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      7\u001b[0m     neuralprocess_pi,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m     print_freq\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m,\n\u001b[1;32m     12\u001b[0m )\n\u001b[1;32m     14\u001b[0m neuralprocess_pi\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m \u001b[43mnp_trainer_pi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/part_III_project/./neural-processes/training.py:118\u001b[0m, in \u001b[0;36mNeuralProcessTrainer.train\u001b[0;34m(self, data_loader, epochs)\u001b[0m\n\u001b[1;32m    116\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_loss(p_y_pred, y_target, q_target, q_context)\n\u001b[1;32m    117\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[0;32m--> 118\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptimizer\u001b[39m.\u001b[39;49mstep()\n\u001b[1;32m    120\u001b[0m epoch_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n\u001b[1;32m    122\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/torch/optim/optimizer.py:140\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m profile_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mOptimizer.step#\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.step\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(obj\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[1;32m    139\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mrecord_function(profile_name):\n\u001b[0;32m--> 140\u001b[0m     out \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    141\u001b[0m     obj\u001b[39m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    142\u001b[0m     \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/torch/optim/optimizer.py:23\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     22\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefaults[\u001b[39m'\u001b[39m\u001b[39mdifferentiable\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m---> 23\u001b[0m     ret \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     24\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     25\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(prev_grad)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/torch/optim/adam.py:234\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure, grad_scaler)\u001b[0m\n\u001b[1;32m    231\u001b[0m                 \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39m`requires_grad` is not supported for `step` in differentiable mode\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    232\u001b[0m             state_steps\u001b[39m.\u001b[39mappend(state[\u001b[39m'\u001b[39m\u001b[39mstep\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m--> 234\u001b[0m     adam(params_with_grad,\n\u001b[1;32m    235\u001b[0m          grads,\n\u001b[1;32m    236\u001b[0m          exp_avgs,\n\u001b[1;32m    237\u001b[0m          exp_avg_sqs,\n\u001b[1;32m    238\u001b[0m          max_exp_avg_sqs,\n\u001b[1;32m    239\u001b[0m          state_steps,\n\u001b[1;32m    240\u001b[0m          amsgrad\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mamsgrad\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    241\u001b[0m          beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[1;32m    242\u001b[0m          beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[1;32m    243\u001b[0m          lr\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mlr\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    244\u001b[0m          weight_decay\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mweight_decay\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    245\u001b[0m          eps\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39meps\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    246\u001b[0m          maximize\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mmaximize\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    247\u001b[0m          foreach\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mforeach\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    248\u001b[0m          capturable\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mcapturable\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    249\u001b[0m          differentiable\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mdifferentiable\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    250\u001b[0m          fused\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mfused\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    251\u001b[0m          grad_scale\u001b[39m=\u001b[39;49mgrad_scale,\n\u001b[1;32m    252\u001b[0m          found_inf\u001b[39m=\u001b[39;49mfound_inf)\n\u001b[1;32m    254\u001b[0m \u001b[39mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/torch/optim/adam.py:300\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    298\u001b[0m     func \u001b[39m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 300\u001b[0m func(params,\n\u001b[1;32m    301\u001b[0m      grads,\n\u001b[1;32m    302\u001b[0m      exp_avgs,\n\u001b[1;32m    303\u001b[0m      exp_avg_sqs,\n\u001b[1;32m    304\u001b[0m      max_exp_avg_sqs,\n\u001b[1;32m    305\u001b[0m      state_steps,\n\u001b[1;32m    306\u001b[0m      amsgrad\u001b[39m=\u001b[39;49mamsgrad,\n\u001b[1;32m    307\u001b[0m      beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[1;32m    308\u001b[0m      beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[1;32m    309\u001b[0m      lr\u001b[39m=\u001b[39;49mlr,\n\u001b[1;32m    310\u001b[0m      weight_decay\u001b[39m=\u001b[39;49mweight_decay,\n\u001b[1;32m    311\u001b[0m      eps\u001b[39m=\u001b[39;49meps,\n\u001b[1;32m    312\u001b[0m      maximize\u001b[39m=\u001b[39;49mmaximize,\n\u001b[1;32m    313\u001b[0m      capturable\u001b[39m=\u001b[39;49mcapturable,\n\u001b[1;32m    314\u001b[0m      differentiable\u001b[39m=\u001b[39;49mdifferentiable,\n\u001b[1;32m    315\u001b[0m      grad_scale\u001b[39m=\u001b[39;49mgrad_scale,\n\u001b[1;32m    316\u001b[0m      found_inf\u001b[39m=\u001b[39;49mfound_inf)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/torch/optim/adam.py:410\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    408\u001b[0m     denom \u001b[39m=\u001b[39m (max_exp_avg_sqs[i]\u001b[39m.\u001b[39msqrt() \u001b[39m/\u001b[39m bias_correction2_sqrt)\u001b[39m.\u001b[39madd_(eps)\n\u001b[1;32m    409\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 410\u001b[0m     denom \u001b[39m=\u001b[39m (exp_avg_sq\u001b[39m.\u001b[39;49msqrt() \u001b[39m/\u001b[39;49m bias_correction2_sqrt)\u001b[39m.\u001b[39;49madd_(eps)\n\u001b[1;32m    412\u001b[0m param\u001b[39m.\u001b[39maddcdiv_(exp_avg, denom, value\u001b[39m=\u001b[39m\u001b[39m-\u001b[39mstep_size)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "neuralprocess_pi = NeuralProcess(dimensions)\n",
    "\n",
    "data_loader = DataLoader(meta_data, batch_size=dimensions['batch_size'], shuffle=True)\n",
    "optimizer = torch.optim.Adam(neuralprocess_pi.parameters(), lr=3e-4)\n",
    "np_trainer_pi = NeuralProcessTrainer(\n",
    "    \"cuda\",\n",
    "    neuralprocess_pi,\n",
    "    optimizer,\n",
    "    num_context_range=(dimensions['num_context'], dimensions['num_context']),\n",
    "    num_extra_target_range=(dimensions['num_target'], dimensions['num_target']),\n",
    "    print_freq=200,\n",
    "    is_lupi=True\n",
    ")\n",
    "\n",
    "neuralprocess_pi.training = True\n",
    "np_trainer_pi.train(data_loader, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(neuralprocess, np_trainer, t_context, y_context, t_target, y_target):\n",
    "    # Switch to test mode\n",
    "    neuralprocess.training = False\n",
    "\n",
    "    # Extract models' distributions over t_target and grid\n",
    "    p_y_pred = neuralprocess(t_context, y_context, t_target)\n",
    "\n",
    "    # flat NP\n",
    "    y_out = p_y_pred.loc.detach().numpy()[0]\n",
    "    var_out = p_y_pred.scale.detach().numpy()[0]\n",
    "\n",
    "    # flat NP reshape\n",
    "    y_out = y_out.reshape((dimensions['max_iter_time'], dimensions['grid_size'], dimensions['grid_size']))\n",
    "    var_out = var_out.reshape((dimensions['max_iter_time'], dimensions['grid_size'], dimensions['grid_size']))\n",
    "\n",
    "    # flat NP result summary\n",
    "    result = [\n",
    "        (y_target[id, :, :], y_out[id, :, :], var_out[id, :, :])\n",
    "        for id in range(y_target.shape[0])\n",
    "    ]\n",
    "\n",
    "    loss = torch.Tensor(np_trainer.epoch_loss_history)\n",
    "\n",
    "    return result, loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select which models to test\n",
    "test_convolutional_neural_process = True\n",
    "test_lupi_neural_process = False\n",
    "test_flat_neural_process = False\n",
    "\n",
    "# Extract a batch from data_loader\n",
    "for batch in data_loader:\n",
    "    break\n",
    "\n",
    "# Use batch to create random set of context points\n",
    "t, y, pi = batch\n",
    "t_context, y_context, _, _, _, _ = context_target_split(\n",
    "    t[0:1], y[0:1], pi[0:1], dimensions['num_context'], dimensions['num_target']\n",
    ")\n",
    "\n",
    "# generate random noise between 0 and 1 to feed as context\n",
    "y_noise = 1 * torch.rand(y_context.shape)\n",
    "\n",
    "# Create a set of target points corresponding to in-sample time range\n",
    "t_target = torch.linspace(0, 1, dimensions['max_iter_time'])\n",
    "t_target = t_target.unsqueeze(1).unsqueeze(0)\n",
    "\n",
    "# Extract mean of distribution\n",
    "t_out = t_target.numpy()[0]\n",
    "\n",
    "# target output\n",
    "y_target = y[0:1][0, :, :]\n",
    "y_target = y_target.reshape((dimensions['max_iter_time'], dimensions['grid_size'], dimensions['grid_size']))\n",
    "\n",
    "if test_lupi_neural_process:\n",
    "    lupi_result, lupi_loss = test_model(neuralprocess_pi, np_trainer_pi, t_context, y_context, t_target, y_target)\n",
    "    lupi_result_noise, _ = test_model(conv_neuralprocess, np_trainer_pi, t_context, y_noise, t_target, y_target)\n",
    "    \n",
    "    torch.save(lupi_result, \"./results/lupi_result.pt\")\n",
    "    torch.save(lupi_loss, \"./results/lupi_loss.pt\")\n",
    "    torch.save(lupi_result_noise, \"./results/lupi_result_noise.pt\")\n",
    "\n",
    "if test_flat_neural_process:\n",
    "    result, loss = test_model(neuralprocess, np_trainer, t_context, y_context, t_target, y_target)\n",
    "    result_noise, _ = test_model(conv_neuralprocess, np_trainer, t_context, y_noise, t_target, y_target)\n",
    "\n",
    "    torch.save(result, \"./results/np_result.pt\")\n",
    "    torch.save(loss, \"./results/loss.pt\")\n",
    "    torch.save(result_noise, \"./results/result_noise.pt\")\n",
    "\n",
    "if test_convolutional_neural_process:\n",
    "    conv_result, conv_loss = test_model(conv_neuralprocess, conv_np_trainer, t_context, y_context, t_target, y_target)\n",
    "    conv_result_noise, _ = test_model(conv_neuralprocess, conv_np_trainer, t_context, y_noise, t_target, y_target)\n",
    "\n",
    "    torch.save(conv_result, \"./results/conv_result.pt\")\n",
    "    torch.save(conv_loss, \"./results/conv_loss.pt\")\n",
    "    torch.save(conv_result_noise, \"./results/conv_result_noise.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert len(result) == dimensions['max_iter_time']\n",
    "# assert len(result[0]) == 3\n",
    "# assert len(lupi_result) == dimensions['max_iter_time']\n",
    "# assert len(lupi_result[0]) == 3\n",
    "assert len(conv_result) == dimensions['max_iter_time']\n",
    "assert len(conv_result[0]) == 3\n",
    "\n",
    "\n",
    "# assert result[0][0].shape == (grid_size, grid_size)\n",
    "# assert result[0][1].shape == (grid_size, grid_size)\n",
    "# assert result[0][2].shape == (grid_size, grid_size)\n",
    "\n",
    "# assert result_noise[0][0].shape == (grid_size, grid_size)\n",
    "# assert result_noise[0][1].shape == (grid_size, grid_size)\n",
    "# assert result_noise[0][2].shape == (grid_size, grid_size)\n",
    "\n",
    "# assert lupi_result[0][0].shape == (grid_size, grid_size)\n",
    "# assert lupi_result[0][1].shape == (grid_size, grid_size)\n",
    "# assert lupi_result[0][2].shape == (grid_size, grid_size)\n",
    "\n",
    "# assert lupi_result_noise[0][0].shape == (grid_size, grid_size)\n",
    "# assert lupi_result_noise[0][1].shape == (grid_size, grid_size)\n",
    "# assert lupi_result_noise[0][2].shape == (grid_size, grid_size)\n",
    "\n",
    "assert conv_result[0][0].shape == (grid_size, grid_size)\n",
    "assert conv_result[0][1].shape == (grid_size, grid_size)\n",
    "assert conv_result[0][2].shape == (grid_size, grid_size)\n",
    "\n",
    "assert conv_result_noise[0][0].shape == (grid_size, grid_size)\n",
    "assert conv_result_noise[0][1].shape == (grid_size, grid_size)\n",
    "assert conv_result_noise[0][2].shape == (grid_size, grid_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metric 1: Mean Accuracy\n",
    "\n",
    "To test how well the model performed, we can calculate the accuracy across the grid using MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance = Performance(\n",
    "    result, dimensions)\n",
    "print(\n",
    "    \"FLAT NP: MSE accuracy was {:.8f}, with variance {:.8f}\".format(\n",
    "        performance.mean_accuracy, performance.var_accuracy\n",
    "    )\n",
    ")\n",
    "\n",
    "lupi_performance = Performance(lupi_result, dimensions)\n",
    "print(\n",
    "    \"LUPI NP: MSE accuracy was {:.8f}, with variance {:.8f}\".format(\n",
    "        lupi_performance.mean_accuracy, lupi_performance.var_accuracy\n",
    "    )\n",
    ")\n",
    "\n",
    "conv_performance = Performance(conv_result, dimensions)\n",
    "print(\n",
    "    \"CONVOLUTION: MSE accuracy was {:.8f}, with variance {:.8f}\".format(\n",
    "        conv_performance.mean_accuracy, performance.var_accuracy\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Losses as Function of Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_losses(loss=loss, lupi_loss=lupi_loss, conv_loss=conv_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fix this bug for GIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_out = y_out.reshape((max_iter_time, grid_size, grid_size))\n",
    "var_out = var_out.reshape((max_iter_time, grid_size, grid_size))\n",
    "y_target = y_target.reshape((max_iter_time, grid_size, grid_size))\n",
    "\n",
    "result = [\n",
    "    (y_target[id, :, :], y_out[id, :, :], var_out[id, :, :])\n",
    "    for id in range(y_target.shape[0])\n",
    "]\n",
    "\n",
    "# from heat_diffusion_dataset import Initial_Conditions, Diffusion_Data\n",
    "# import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from matplotlib.animation import FuncAnimation\n",
    "\n",
    "\n",
    "def plotheatmap(result_k, k, axes):\n",
    "    # Clear the current plot figure\n",
    "    plt.clf()\n",
    "    ax1, ax2, ax3 = axes\n",
    "\n",
    "    # plt.title(f\"Temperature at t = {k * delta_t:.3f} unit time\")\n",
    "    ax1.set_title(f\"Target at t = {k * 4 * np.pi / max_iter_time:.3f} unit time\")\n",
    "    ax1.set_xlabel(\"x\")\n",
    "    ax1.set_ylabel(\"y\")\n",
    "\n",
    "    ax2.set_title(\n",
    "        f\"Predicted Mean at t = {k * 4 * np.pi / max_iter_time:.3f} unit time\"\n",
    "    )\n",
    "    ax2.set_xlabel(\"x\")\n",
    "    ax2.set_ylabel(\"y\")\n",
    "\n",
    "    ax3.set_title(f\"Predicted Var at t = {k * 4 * np.pi / max_iter_time:.3f} unit time\")\n",
    "    ax3.set_xlabel(\"x\")\n",
    "    ax3.set_ylabel(\"y\")\n",
    "\n",
    "    # This is to plot u_k (u at time-step k)\n",
    "    ax1.pcolormesh(result_k[0], cmap=plt.cm.jet, vmin=-1.1, vmax=1.1)\n",
    "    ax2.pcolormesh(result_k[1], cmap=plt.cm.jet, vmin=-1.1, vmax=1.1)\n",
    "    ax3.pcolormesh(result_k[2], cmap=plt.cm.jet, vmin=-1.1, vmax=1.1)\n",
    "\n",
    "    return fig, axes\n",
    "\n",
    "\n",
    "def animate(k):\n",
    "    plotheatmap(result[k], k)\n",
    "\n",
    "    # if not plot_var and not target:\n",
    "    #     plotheatmap(y_out[k], k, delta_t)\n",
    "    # elif plot_var and not target:\n",
    "    #     plotheatmap(var_out[k], k, delta_t)\n",
    "    # else:\n",
    "    #     plotheatmap(y_target[k], k, delta_t)\n",
    "\n",
    "\n",
    "# plot_var = False\n",
    "# target = False\n",
    "fig, axes = plt.subplots(ncols=3, figsize=(15, 4))\n",
    "\n",
    "anim = animation.FuncAnimation(\n",
    "    fig, animate, interval=1, frames=max_iter_time, repeat=False, fargs=(axes,)\n",
    ")\n",
    "anim.save(\"harmonics_solution.gif\")\n",
    "\n",
    "# plot_var=True\n",
    "# anim = animation.FuncAnimation(plt.figure(), animate, interval=1, frames=max_iter_time, repeat=False, fargs=None)\n",
    "# anim.save(\"harmonics_variance.gif\")\n",
    "\n",
    "# target=True\n",
    "# anim = animation.FuncAnimation(plt.figure(), animate, interval=1, frames=max_iter_time, repeat=False, fargs=None)\n",
    "# anim.save(\"harmonics_target.gif\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
