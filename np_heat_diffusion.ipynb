{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Notebook\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The task is to produce a neural process which is tailored to solve a physical system.  In this case, the physical system to be solved is the heat diffusion across a two-dimensional grid.  There are three main changes I wish to make to the standard neural process.  These are listed below, along with a brief description of their physical motivation.\n",
    "\n",
    "#### 1. Convolutional Encoder and Decoder block \n",
    "Spatial equivariance is built into the system, since the heat diffusion function does not have a spatially dependent forcing term.  All terms are based on derivatives, which means the solution obeys spatial equivariance.  I hope to replicate this feature in the architecture, allowing for an easier learning process.\n",
    "#### 2. Learning using Privileged Information\n",
    "Learning using privileged information (LUPI) allows the model, while training, to have access to `privileged information' (PI).  PI could be anything important the model should be aware of.  For example, if the total energy in the grid is conserved, imput this as PI.  When it comes to test time, the model does not have access to any PI.  The hope is that the model can infer what the PI should be (e.g. by figuring out what the total energy is and conserving it), making for a faster learning process.  There is a wide variety of PI to be used and experimented with.  A few more examples are: initial conditions, final conditions, decay constant, entropy measure.\n",
    "\n",
    "The way the PI is implemented is through an encoder which runs separately to the usual encoder.  The PI embedding is then aggregated with the embedding of the data using a residual neural network; we do not want the PI to dominate the learning, but merely to add a `first order correction' to the learning process.  The good thing about this structure is that the PI can be added to any encoder block (e.g. flat encoder or convolutional encoder)\n",
    "\n",
    "#### 3. Time-Order Respecting Aggregator\n",
    "In a neural process, the embeddings of the data at different times, $t_i$, are aggregated with a permutation invariant aggregator.  This is not usually useful for physical processes, as there tends to be a time-respecting process such as increase in entropy (in this case, diffusion of heat).  Therefore, it might be useful to reflect this in the aggregator.  The aggregator is such that there is no information leak from future to past - it imposes causality.\n",
    "\n",
    "The aggregator could also be designed to reflect temporal equivariance, for the same reasons as the spatial equivariance: the diffusion equation involves no terms which depend explicitly on time, but rather only the derivative with resepct to time.  If the model is temporally equivariant, it may perform much better on extrapolation tasks (as it is not completely `blind' when it heads out of the sample, having learnt temporal behaviour)\n",
    "\n",
    "One possible choice for this is to allow the model to `learn' these features by implementing a multi-head attention network.  However, with this option there is far less control over which physical concepts I am imposing.\n",
    "\n",
    "\n",
    "I hope these three changes will improve on the most basic vanilla neural process architecture to learn the heat diffusion behaviour over a two-dimensional grid, as they are all grounded in physical concepts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from scipy.integrate import odeint\n",
    "\n",
    "\n",
    "# grab the neural process functions from Emilien Dupont's library called neural-processes\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, \"./neural-processes\")\n",
    "\n",
    "# neural_process.py and training.py exist in neural-processes folder\n",
    "import neural_process\n",
    "from neural_process import NeuralProcessConv, NeuralProcess, NeuralProcessImg\n",
    "from training import NeuralProcessTrainer\n",
    "from utils import context_target_split\n",
    "from heat_diffusion_dataset import Initial_Conditions, Diffusion_Data, RestoredData\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diffusion Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimensions = {\n",
    "    't_dim' : 1,\n",
    "    'y_dim' : 2500,\n",
    "    'r_dim' : 500,\n",
    "    'z_dim' : 500,\n",
    "    'h_dim' : 500,\n",
    "    'z_dim' : 500,\n",
    "    'pi_dim' : 4,\n",
    "    'max_iter_time' : 100,\n",
    "    'grid_size' : 50,\n",
    "    'num_samples' : 40,  # why do I need this one...\n",
    "    'num_context' : 40,\n",
    "    'num_target' : 40,\n",
    "    'batch_size' : 2,\n",
    "    'num_channels' : 512,\n",
    "    'tcn_kernel_size' : 5,\n",
    "}\n",
    "\n",
    "assert dimensions['grid_size']**2 == dimensions['y_dim']\n",
    "assert dimensions['tcn_kernel_size'] % 2 == 1\n",
    "\n",
    "# parameters\n",
    "grid_size = dimensions['grid_size']\n",
    "num_samples = dimensions['num_samples']\n",
    "square_range = (5, 10)\n",
    "temp_range = (0.7, 1.0)\n",
    "diffusion_coef = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "RUN TO RE-GENERATE DATA\n",
    "'''\n",
    "\n",
    "initial_conditions = Initial_Conditions(\n",
    "    max_iter_time=dimensions['max_iter_time'], grid_size=grid_size\n",
    ")\n",
    "\n",
    "process_dataset = Diffusion_Data(\n",
    "    num_samples=num_samples,\n",
    "    max_iter_time=dimensions['max_iter_time'],\n",
    "    grid_size=grid_size,\n",
    "    initial_conditions=initial_conditions,\n",
    "    square_range=square_range,\n",
    "    temp_range=temp_range,\n",
    "    diffusion_coef=diffusion_coef,\n",
    "    pi_dim=dimensions['pi_dim']\n",
    ")\n",
    "\n",
    "# plot target data\n",
    "# process_dataset.visualise_solution(max_iter_time=dimensions['max_iter_time'], show_until=30)\n",
    "\n",
    "time_array = process_dataset.time_array\n",
    "\n",
    "# process_dataset.save_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "RUN TO READ DATA\n",
    "'''\n",
    "\n",
    "dataset = RestoredData(\n",
    "    num_samples=dimensions['num_samples'],\n",
    "    max_iter_time=dimensions['max_iter_time'],\n",
    "    grid_size=dimensions['grid_size'],\n",
    "    temp_range=temp_range\n",
    ")\n",
    "\n",
    "pure_noise = dataset.generate_noise()\n",
    "\n",
    "time_array = dataset.time_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VANILLA NEURAL PROCESS TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Avg_loss: 78513.87935791016\n",
      "Epoch: 1, Avg_loss: 16173.517932128907\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [6], line 15\u001b[0m\n\u001b[1;32m      5\u001b[0m np_trainer \u001b[38;5;241m=\u001b[39m NeuralProcessTrainer(\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      7\u001b[0m     neuralprocess,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m     print_freq\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m,\n\u001b[1;32m     12\u001b[0m )\n\u001b[1;32m     14\u001b[0m neuralprocess\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m \u001b[43mnp_trainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Programming/PART_III_PROJECT/heat_diffusion/./neural-processes/training.py:137\u001b[0m, in \u001b[0;36mNeuralProcessTrainer.train\u001b[0;34m(self, data_loader, epochs)\u001b[0m\n\u001b[1;32m    135\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_loss(p_y_pred, y_target, q_target, q_context)\n\u001b[1;32m    136\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[0;32m--> 137\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptimizer\u001b[39m.\u001b[39;49mstep()\n\u001b[1;32m    139\u001b[0m epoch_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n\u001b[1;32m    141\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/torch/optim/optimizer.py:140\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m profile_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mOptimizer.step#\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.step\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(obj\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[1;32m    139\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mrecord_function(profile_name):\n\u001b[0;32m--> 140\u001b[0m     out \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    141\u001b[0m     obj\u001b[39m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    142\u001b[0m     \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/torch/optim/optimizer.py:23\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     22\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefaults[\u001b[39m'\u001b[39m\u001b[39mdifferentiable\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m---> 23\u001b[0m     ret \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     24\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     25\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(prev_grad)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/torch/optim/adam.py:234\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure, grad_scaler)\u001b[0m\n\u001b[1;32m    231\u001b[0m                 \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39m`requires_grad` is not supported for `step` in differentiable mode\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    232\u001b[0m             state_steps\u001b[39m.\u001b[39mappend(state[\u001b[39m'\u001b[39m\u001b[39mstep\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m--> 234\u001b[0m     adam(params_with_grad,\n\u001b[1;32m    235\u001b[0m          grads,\n\u001b[1;32m    236\u001b[0m          exp_avgs,\n\u001b[1;32m    237\u001b[0m          exp_avg_sqs,\n\u001b[1;32m    238\u001b[0m          max_exp_avg_sqs,\n\u001b[1;32m    239\u001b[0m          state_steps,\n\u001b[1;32m    240\u001b[0m          amsgrad\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mamsgrad\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    241\u001b[0m          beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[1;32m    242\u001b[0m          beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[1;32m    243\u001b[0m          lr\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mlr\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    244\u001b[0m          weight_decay\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mweight_decay\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    245\u001b[0m          eps\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39meps\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    246\u001b[0m          maximize\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mmaximize\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    247\u001b[0m          foreach\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mforeach\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    248\u001b[0m          capturable\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mcapturable\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    249\u001b[0m          differentiable\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mdifferentiable\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    250\u001b[0m          fused\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mfused\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    251\u001b[0m          grad_scale\u001b[39m=\u001b[39;49mgrad_scale,\n\u001b[1;32m    252\u001b[0m          found_inf\u001b[39m=\u001b[39;49mfound_inf)\n\u001b[1;32m    254\u001b[0m \u001b[39mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/torch/optim/adam.py:300\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    298\u001b[0m     func \u001b[39m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 300\u001b[0m func(params,\n\u001b[1;32m    301\u001b[0m      grads,\n\u001b[1;32m    302\u001b[0m      exp_avgs,\n\u001b[1;32m    303\u001b[0m      exp_avg_sqs,\n\u001b[1;32m    304\u001b[0m      max_exp_avg_sqs,\n\u001b[1;32m    305\u001b[0m      state_steps,\n\u001b[1;32m    306\u001b[0m      amsgrad\u001b[39m=\u001b[39;49mamsgrad,\n\u001b[1;32m    307\u001b[0m      beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[1;32m    308\u001b[0m      beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[1;32m    309\u001b[0m      lr\u001b[39m=\u001b[39;49mlr,\n\u001b[1;32m    310\u001b[0m      weight_decay\u001b[39m=\u001b[39;49mweight_decay,\n\u001b[1;32m    311\u001b[0m      eps\u001b[39m=\u001b[39;49meps,\n\u001b[1;32m    312\u001b[0m      maximize\u001b[39m=\u001b[39;49mmaximize,\n\u001b[1;32m    313\u001b[0m      capturable\u001b[39m=\u001b[39;49mcapturable,\n\u001b[1;32m    314\u001b[0m      differentiable\u001b[39m=\u001b[39;49mdifferentiable,\n\u001b[1;32m    315\u001b[0m      grad_scale\u001b[39m=\u001b[39;49mgrad_scale,\n\u001b[1;32m    316\u001b[0m      found_inf\u001b[39m=\u001b[39;49mfound_inf)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/torch/optim/adam.py:410\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    408\u001b[0m     denom \u001b[39m=\u001b[39m (max_exp_avg_sqs[i]\u001b[39m.\u001b[39msqrt() \u001b[39m/\u001b[39m bias_correction2_sqrt)\u001b[39m.\u001b[39madd_(eps)\n\u001b[1;32m    409\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 410\u001b[0m     denom \u001b[39m=\u001b[39m (exp_avg_sq\u001b[39m.\u001b[39;49msqrt() \u001b[39m/\u001b[39m bias_correction2_sqrt)\u001b[39m.\u001b[39madd_(eps)\n\u001b[1;32m    412\u001b[0m param\u001b[39m.\u001b[39maddcdiv_(exp_avg, denom, value\u001b[39m=\u001b[39m\u001b[39m-\u001b[39mstep_size)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "neuralprocess = NeuralProcess(dimensions)\n",
    "\n",
    "data_loader = DataLoader(dataset, batch_size=dimensions['batch_size'], shuffle=True)\n",
    "optimizer = torch.optim.Adam(neuralprocess.parameters(), lr=3e-4)\n",
    "np_trainer = NeuralProcessTrainer(\n",
    "    \"cuda\",\n",
    "    neuralprocess,\n",
    "    optimizer,\n",
    "    num_context_range=(dimensions['num_context'], dimensions['num_context']),\n",
    "    num_extra_target_range=(dimensions['num_target'], dimensions['num_target']),\n",
    "    print_freq=200,\n",
    ")\n",
    "\n",
    "neuralprocess.training = True\n",
    "np_trainer.train(data_loader, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CONVOLUTIONAL NEURAL PROCESS TRAINING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameters\n",
    "- h_dim\n",
    "- r_dim\n",
    "- z_dim\n",
    "- batch_size\n",
    "- num_context\n",
    "- num_target\n",
    "- lr\n",
    "\n",
    "#### Hidden Hyperparameters\n",
    "- Number of linear layers after convolution in Net\n",
    "- Number of linear layers in TransposeConvNet\n",
    "- Number of channels in Net and TransposeConvNet\n",
    "- Number of layers in Net and TransposeConvNet\n",
    "- Kernels, Dilations, Paddings\n",
    "\n",
    "#### Current Convolution Summary \n",
    "\n",
    "Net: 2 layers with 32 'hidden' channels, followed by 3 Linear layers with h_dim hidden.\n",
    "\n",
    "TNet: 1 Linear layer, followed by 2 transpose convolutional layers with 32 'hidden' channels.\n",
    "\n",
    "\n",
    "#### Purpose of the Convolution\n",
    "- Create spatially equivariant features in the grids\n",
    "- Encourage principles of locality when learning\n",
    "- Temporal equivariance in solution (periodicity encouraged?) - this is not happening currently as the temporal aspect only enters after the convolution\n",
    "\n",
    "TODO: before moving on \n",
    "- Debug the conv neural process (write some tests?)\n",
    "- Implement tests on standard NP \n",
    "- Compare performance  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() takes 2 positional arguments but 7 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [7], line 7\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\" \u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03mTODO \u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m- put time into channels not flat layer DONE - also kept in flat layer\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m- play with hyperparams until good outcome \u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m conv_neuralprocess \u001b[38;5;241m=\u001b[39m \u001b[43mNeuralProcessConv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdimensions\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mt_dim\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdimensions\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43my_dim\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdimensions\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr_dim\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdimensions\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mz_dim\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdimensions\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mh_dim\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdimensions\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgrid_size\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m data_loader \u001b[38;5;241m=\u001b[39m DataLoader(dataset, batch_size\u001b[38;5;241m=\u001b[39mdimensions[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m'\u001b[39m], shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     12\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(conv_neuralprocess\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3e-4\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() takes 2 positional arguments but 7 were given"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "TODO \n",
    "- put time into channels not flat layer DONE - also kept in flat layer\n",
    "- play with hyperparams until good outcome \n",
    "\"\"\"\n",
    "\n",
    "conv_neuralprocess = NeuralProcessConv(\n",
    "    dimensions['t_dim'], dimensions['y_dim'], dimensions['r_dim'], dimensions['z_dim'], dimensions['h_dim'], dimensions['grid_size']\n",
    ")\n",
    "\n",
    "data_loader = DataLoader(dataset, batch_size=dimensions['batch_size'], shuffle=True)\n",
    "optimizer = torch.optim.Adam(conv_neuralprocess.parameters(), lr=3e-4)\n",
    "conv_np_trainer = NeuralProcessTrainer(\n",
    "    \"cuda\",\n",
    "    conv_neuralprocess,\n",
    "    optimizer,\n",
    "    num_context_range=(dimensions['num_context'], dimensions['num_context']),\n",
    "    num_extra_target_range=(dimensions['num_target'], dimensions['num_target']),\n",
    "    print_freq=200,\n",
    "    grid_size=grid_size,\n",
    ")\n",
    "\n",
    "conv_neuralprocess.training = True\n",
    "conv_np_trainer.train(data_loader, 120)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L.U.P.I. FOR FLAT NP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Avg_loss: 85659.2748046875\n",
      "Epoch: 1, Avg_loss: -10707.619189453126\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [8], line 15\u001b[0m\n\u001b[1;32m      5\u001b[0m np_trainer_pi \u001b[38;5;241m=\u001b[39m NeuralProcessTrainer(\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      7\u001b[0m     neuralprocess_pi,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m     print_freq\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m,\n\u001b[1;32m     12\u001b[0m )\n\u001b[1;32m     14\u001b[0m neuralprocess_pi\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m \u001b[43mnp_trainer_pi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Programming/PART_III_PROJECT/heat_diffusion/./neural-processes/training.py:136\u001b[0m, in \u001b[0;36mNeuralProcessTrainer.train\u001b[0;34m(self, data_loader, epochs)\u001b[0m\n\u001b[1;32m    126\u001b[0m     p_y_pred, q_target, q_context \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mneural_process(\n\u001b[1;32m    127\u001b[0m         x_context,\n\u001b[1;32m    128\u001b[0m         y_context,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    132\u001b[0m         pi_target\u001b[39m=\u001b[39mpi_target,\n\u001b[1;32m    133\u001b[0m     )\n\u001b[1;32m    135\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_loss(p_y_pred, y_target, q_target, q_context)\n\u001b[0;32m--> 136\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m    137\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m    139\u001b[0m epoch_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/torch/_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    479\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    480\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    481\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    486\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    487\u001b[0m     )\n\u001b[0;32m--> 488\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    489\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    490\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/torch/autograd/__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    194\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    198\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    199\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "neuralprocess_pi = NeuralProcess(dimensions)\n",
    "\n",
    "data_loader = DataLoader(dataset, batch_size=dimensions['batch_size'], shuffle=True)\n",
    "optimizer = torch.optim.Adam(neuralprocess_pi.parameters(), lr=3e-4)\n",
    "np_trainer_pi = NeuralProcessTrainer(\n",
    "    \"cuda\",\n",
    "    neuralprocess_pi,\n",
    "    optimizer,\n",
    "    num_context_range=(dimensions['num_context'], dimensions['num_context']),\n",
    "    num_extra_target_range=(dimensions['num_target'], dimensions['num_target']),\n",
    "    print_freq=200,\n",
    ")\n",
    "\n",
    "neuralprocess_pi.training = True\n",
    "np_trainer_pi.train(data_loader, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import context_target_split\n",
    "\n",
    "# Select which models to test\n",
    "test_convolutional_neural_process = False\n",
    "test_lupi_neural_process = False\n",
    "test_flat_neural_process = True\n",
    "\n",
    "# Extract a batch from data_loader\n",
    "for batch in data_loader:\n",
    "    break\n",
    "\n",
    "# Use batch to create random set of context points\n",
    "t, y, pi = batch\n",
    "t_context, y_context, _, _, _, _ = context_target_split(\n",
    "    t[0:1], y[0:1], pi[0:1], dimensions['num_context'], dimensions['num_target']\n",
    ")\n",
    "\n",
    "# Create a set of target points corresponding to in-sample time range\n",
    "t_target = torch.linspace(0, 1, dimensions['max_iter_time'])\n",
    "t_target = t_target.unsqueeze(1).unsqueeze(0)\n",
    "\n",
    "# Extract mean of distribution\n",
    "t_out = t_target.numpy()[0]\n",
    "\n",
    "# target output\n",
    "y_target = y[0:1][0, :, :]\n",
    "y_target = y_target.reshape((dimensions['max_iter_time'], dimensions['grid_size'], dimensions['grid_size']))\n",
    "\n",
    "if test_lupi_neural_process:\n",
    "    # Switch to test mode\n",
    "    neuralprocess_pi.training = False\n",
    "\n",
    "    # Extract models' distributions over t_target and grid\n",
    "    p_y_pred = neuralprocess_pi(t_context, y_context, t_target)\n",
    "\n",
    "    # flat NP\n",
    "    y_out = p_y_pred.loc.detach().numpy()[0]\n",
    "    var_out = p_y_pred.scale.detach().numpy()[0]\n",
    "\n",
    "    # flat NP reshape\n",
    "    y_out = y_out.reshape((dimensions['max_iter_time'], dimensions['grid_size'], dimensions['grid_size']))\n",
    "    var_out = var_out.reshape((dimensions['max_iter_time'], dimensions['grid_size'], dimensions['grid_size']))\n",
    "\n",
    "    # flat NP result summary\n",
    "    result = [\n",
    "        (y_target[id, :, :], y_out[id, :, :], var_out[id, :, :])\n",
    "        for id in range(y_target.shape[0])\n",
    "    ]\n",
    "\n",
    "    torch.save(result, \"./results/result.pt\")\n",
    "\n",
    "if test_flat_neural_process:\n",
    "    # Switch to test mode\n",
    "    neuralprocess.training = False\n",
    "\n",
    "    # Extract models' distributions over t_target and grid\n",
    "    p_y_pred = neuralprocess(t_context, y_context, t_target)\n",
    "\n",
    "    # flat NP\n",
    "    y_out = p_y_pred.loc.detach().numpy()[0]\n",
    "    var_out = p_y_pred.scale.detach().numpy()[0]\n",
    "\n",
    "    # flat NP reshape\n",
    "    y_out = y_out.reshape((dimensions['max_iter_time'], dimensions['grid_size'], dimensions['grid_size']))\n",
    "    var_out = var_out.reshape((dimensions['max_iter_time'], dimensions['grid_size'], dimensions['grid_size']))\n",
    "\n",
    "    # flat NP result summary\n",
    "    result = [\n",
    "        (y_target[id, :, :], y_out[id, :, :], var_out[id, :, :])\n",
    "        for id in range(y_target.shape[0])\n",
    "    ]\n",
    "\n",
    "    torch.save(result, \"./results/np_result.pt\")\n",
    "\n",
    "\n",
    "if test_convolutional_neural_process:\n",
    "    conv_neuralprocess.training = False\n",
    "\n",
    "    conv_p_y_pred = conv_neuralprocess(t_context, y_context, t_target)\n",
    "\n",
    "    # convolutional NP\n",
    "    conv_y_out = conv_p_y_pred.loc.detach().numpy()[0]\n",
    "    conv_var_out = conv_p_y_pred.scale.detach().numpy()[0]\n",
    "    # convolutional NP reshape\n",
    "    conv_y_out = conv_y_out.reshape((dimensions['max_iter_time'], dimensions['grid_size'], dimensions['grid_size']))\n",
    "    conv_var_out = conv_var_out.reshape((dimensions['max_iter_time'], dimensions['grid_size'], dimensions['grid_size']))\n",
    "    # convolutional NP result summary\n",
    "    conv_result = [\n",
    "        (y_target[id, :, :], conv_y_out[id, :, :], conv_var_out[id, :, :])\n",
    "        for id in range(y_target.shape[0])\n",
    "    ]\n",
    "    torch.save(conv_result, \"./results/conv_result.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding Model Learning Processes\n",
    "\n",
    "#### Input noise into the model and see what its characteristics are \n",
    "#### Plot the losses as as function of epochs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Switch to test mode\n",
    "neuralprocess.training = False\n",
    "\n",
    "# Extract models' distributions over t_target and grid\n",
    "p_y_pred = neuralprocess(t_context, y_context, t_target)\n",
    "\n",
    "# flat NP\n",
    "y_out = p_y_pred.loc.detach().numpy()[0]\n",
    "var_out = p_y_pred.scale.detach().numpy()[0]\n",
    "\n",
    "# flat NP reshape\n",
    "y_out = y_out.reshape((max_iter_time, grid_size, grid_size))\n",
    "var_out = var_out.reshape((max_iter_time, grid_size, grid_size))\n",
    "\n",
    "# flat NP result summary\n",
    "result = [\n",
    "    (y_target[id, :, :], y_out[id, :, :], var_out[id, :, :])\n",
    "    for id in range(y_target.shape[0])\n",
    "]\n",
    "\n",
    "'''\n",
    "Loss Plots\n",
    "'''\n",
    "\n",
    "epoch_loss = torch.Tensor(np_trainer.epoch_loss_history)\n",
    "torch.save(epoch_loss, \"./results/epoch_loss_flat.pt\")\n",
    "\n",
    "# epoch_loss_pi = torch.Tensor(np_trainer_pi.epoch_loss_history)\n",
    "# torch.save(epoch_loss, \"./results/epoch_loss_pi.pt\")\n",
    "\n",
    "# epoch_loss_conv = torch.Tensor(conv_np_trainer.epoch_loss_history)\n",
    "# torch.save(epoch_loss, \"./results/epoch_loss_conv.pt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fix this bug for GIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_out = y_out.reshape((max_iter_time, grid_size, grid_size))\n",
    "var_out = var_out.reshape((max_iter_time, grid_size, grid_size))\n",
    "y_target = y_target.reshape((max_iter_time, grid_size, grid_size))\n",
    "\n",
    "result = [\n",
    "    (y_target[id, :, :], y_out[id, :, :], var_out[id, :, :])\n",
    "    for id in range(y_target.shape[0])\n",
    "]\n",
    "\n",
    "# from heat_diffusion_dataset import Initial_Conditions, Diffusion_Data\n",
    "# import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from matplotlib.animation import FuncAnimation\n",
    "\n",
    "\n",
    "def plotheatmap(result_k, k, axes):\n",
    "    # Clear the current plot figure\n",
    "    plt.clf()\n",
    "    ax1, ax2, ax3 = axes\n",
    "\n",
    "    # plt.title(f\"Temperature at t = {k * delta_t:.3f} unit time\")\n",
    "    ax1.set_title(f\"Target at t = {k * 4 * np.pi / max_iter_time:.3f} unit time\")\n",
    "    ax1.set_xlabel(\"x\")\n",
    "    ax1.set_ylabel(\"y\")\n",
    "\n",
    "    ax2.set_title(\n",
    "        f\"Predicted Mean at t = {k * 4 * np.pi / max_iter_time:.3f} unit time\"\n",
    "    )\n",
    "    ax2.set_xlabel(\"x\")\n",
    "    ax2.set_ylabel(\"y\")\n",
    "\n",
    "    ax3.set_title(f\"Predicted Var at t = {k * 4 * np.pi / max_iter_time:.3f} unit time\")\n",
    "    ax3.set_xlabel(\"x\")\n",
    "    ax3.set_ylabel(\"y\")\n",
    "\n",
    "    # This is to plot u_k (u at time-step k)\n",
    "    ax1.pcolormesh(result_k[0], cmap=plt.cm.jet, vmin=-1.1, vmax=1.1)\n",
    "    ax2.pcolormesh(result_k[1], cmap=plt.cm.jet, vmin=-1.1, vmax=1.1)\n",
    "    ax3.pcolormesh(result_k[2], cmap=plt.cm.jet, vmin=-1.1, vmax=1.1)\n",
    "\n",
    "    return fig, axes\n",
    "\n",
    "\n",
    "def animate(k):\n",
    "    plotheatmap(result[k], k)\n",
    "\n",
    "    # if not plot_var and not target:\n",
    "    #     plotheatmap(y_out[k], k, delta_t)\n",
    "    # elif plot_var and not target:\n",
    "    #     plotheatmap(var_out[k], k, delta_t)\n",
    "    # else:\n",
    "    #     plotheatmap(y_target[k], k, delta_t)\n",
    "\n",
    "\n",
    "# plot_var = False\n",
    "# target = False\n",
    "fig, axes = plt.subplots(ncols=3, figsize=(15, 4))\n",
    "\n",
    "anim = animation.FuncAnimation(\n",
    "    fig, animate, interval=1, frames=max_iter_time, repeat=False, fargs=(axes,)\n",
    ")\n",
    "anim.save(\"harmonics_solution.gif\")\n",
    "\n",
    "# plot_var=True\n",
    "# anim = animation.FuncAnimation(plt.figure(), animate, interval=1, frames=max_iter_time, repeat=False, fargs=None)\n",
    "# anim.save(\"harmonics_variance.gif\")\n",
    "\n",
    "# target=True\n",
    "# anim = animation.FuncAnimation(plt.figure(), animate, interval=1, frames=max_iter_time, repeat=False, fargs=None)\n",
    "# anim.save(\"harmonics_target.gif\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
